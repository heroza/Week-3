{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Week-3/blob/main/borderline%20after%20smote%20on%20feature%20space%20under70_128px.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "9ae16fad-cecb-4b5f-aac3-aacd5dfffacc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_x4c0_DTkaa"
      },
      "source": [
        "#Library, atribut, and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nR2MJBYq-oiB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE, SVMSMOTE, ADASYN, KMeansSMOTE, BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 128\n",
        "IMAGE_H = 128\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)\n",
        "num_classes = 7\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "opt_SGD = SGD(learning_rate=0.001)\n",
        "the_arch = 'resnet50'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JffFid9sOXeo"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset\n",
        "def preprocess_image_input(input_images, arch = the_arch):\n",
        "  input_images = input_images.astype('float32')\n",
        "  if arch == 'inception_v3':\n",
        "    output_ims = tf.keras.applications.inception_v3.preprocess_input(input_images)\n",
        "  else:\n",
        "    output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n",
        "\n",
        "def load_cifar10_dataset():\n",
        "  from keras.datasets import cifar10\n",
        "    # load dataset\n",
        "  (X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "    # one hot encode target values\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def true_positive(l1,l2):\n",
        "  tp = 0\n",
        "  for i in range(len(l1)):\n",
        "    tp = tf.cond(l1[i]==l2[i]==1, lambda: tp+1)\n",
        "  return tp\n",
        "\n",
        "def true_negative(l1,l2):\n",
        "  tn = 0\n",
        "  for i in range(len(l1)):\n",
        "    tn = tf.cond(l1[i]==l2[i]==0, lambda: tn+1)\n",
        "  return tn\n",
        "\n",
        "def false_positive(l1,l2):\n",
        "  fp = 0\n",
        "  for i in range(len(l1)):\n",
        "    fp = tf.cond(l1[i] != l2[i] and l2[i]==1, lambda: fp+1)\n",
        "  return fp\n",
        "\n",
        "def false_negative(l1,l2):\n",
        "  fn = 0\n",
        "  for i in range(len(l1)):\n",
        "    fn = tf.cond(l1[i] != l2[i] and l2[i] == 0, lambda: fn+1)\n",
        "  return fn\n",
        "\n",
        "def balanced_acc2(y_true,y_pred):\n",
        "  \n",
        "  a = y_true.numpy()\n",
        "  b = y_pred.numpy()\n",
        "  return balanced_accuracy_score(a,b)\n",
        "\n",
        "def balanced_acc(y_true,y_pred):\n",
        "    from keras import backend as K\n",
        "    tensor1 = tf.math.argmax(y_true, axis=1)\n",
        "    tensor2 = tf.math.argmax(y_pred, axis=1)\n",
        "    cm = tf.math.confusion_matrix(tensor1, tensor2)\n",
        "    diag = tf.linalg.tensor_diag_part (cm)\n",
        "    tpfn = tf.cast(K.sum(cm, axis = 1), tf.float32) + K.epsilon()\n",
        "    recall = tf.divide(tf.cast(diag, tf.float32),tpfn)\n",
        "    balanced_acc = K.mean(recall)\n",
        "    balanced_acc = K.mean(balanced_acc)\n",
        "\n",
        "    return balanced_acc\n",
        "\n",
        "def define_base_model(arch = the_arch, start_trainable_layer = 9999, attention=False):\n",
        "  #x = data_augmentation(input_tensor)\n",
        "  #x = layers.Rescaling(1.0 / 255)(input_tensor)  # Rescale inputs\n",
        "  if arch != 'dense':\n",
        "    input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "    #x = UpSampling2D(size=(7,7))(input_tensor)\n",
        "    if arch == 'resnet50':\n",
        "      base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'inception_v3':\n",
        "      base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'ResNet':\n",
        "      base_model = ResNet(classes ,image_shape)(input_tensor)\n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "    if start_trainable_layer != 9999:\n",
        "      for layer in base_model.layers[start_trainable_layer:]:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    x = base_model.output\n",
        "    if attention:\n",
        "      x = Attention(1024,1024,7,8)(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Flatten()(x)\n",
        "  else:\n",
        "    input_tensor = Input(shape=(2048))\n",
        "    x = input_tensor\n",
        "  #x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  #x = Dropout(0.2)(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "def define_model_resnet():\n",
        "  input_shape = (IMAGE_H, IMAGE_W, 3)\n",
        "  input_tensor = Input(shape=input_shape)\n",
        "  x = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)(input_tensor, training=False)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "# scale pixels\n",
        "def norm_pixels(train, test):\n",
        "    # convert from integers to floats\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm = test.astype('float32')\n",
        "    # normalize to range 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "    # return normalized images\n",
        "    return train_norm, test_norm\n",
        "\n",
        "def load_isic2018_dataset(train_under_frac = 0):\n",
        "  df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "  df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "\n",
        "  #decode one hot label\n",
        "  df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "  df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "  #random undersampling for training dataset\n",
        "  if train_under_frac !=0:\n",
        "    df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=train_under_frac).index)\n",
        "\n",
        "  #drop one-hot column\n",
        "  df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "  df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "  #make filepaths of the image\n",
        "  dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "  dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "  df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "  df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'\n",
        "  \n",
        "  #load image pixels to dataframe\n",
        "  df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "  df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def reset_dataset(df_train, df_val):\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train, the_arch)\n",
        "  X_val = preprocess_image_input(X_val, the_arch)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def SMOTE_Data(X, y, one_hot = False, k = 5, width = IMAGE_W, height = IMAGE_H, c = 3, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  \n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape(-1, width * height * c), y)\n",
        "  X_resampled = X_resampled.reshape(-1, width, height, c)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled\n",
        "\n",
        "def SMOTE_Data2(X, y, one_hot = False, k = 5, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k, sampling_strategy={0:2500,1:2500,2:2500,3:2500,4:2500,5:2500,6:2500})\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE9FCWBe8deT"
      },
      "source": [
        "#Inner-Borderline SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3UnuaKz8kzJ"
      },
      "outputs": [],
      "source": [
        "def get_class(X, y, c):\n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    return xbeg, ybeg\n",
        "def find_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = xclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "    yclass = yclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "\n",
        "    return xclass, yclass\n",
        "def find_inner_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      if y[i] != cli:\n",
        "        ret.append(n_neigh)  \n",
        "      else:\n",
        "        ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    is_border = np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))\n",
        "    \n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(is_border[ind[i,j]] for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = X[np.logical_and(np.logical_not(is_border),ret > 0)]\n",
        "    yclass = y[np.logical_and(np.logical_not(is_border),ret > 0)]\n",
        "    return xclass, yclass\n",
        "\n",
        "def G_SM(xclass,n_to_sample,cl, n_neigh = 6):\n",
        "    \n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(xclass)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(xclass))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = xclass[base_indices]\n",
        "    X_neighbor = xclass[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def Borderline_SMOTE(X_train, y_train, random_state=42, k_neighbors=5, start=0, n=7):\n",
        "  #reshape X_train\n",
        "  X_train = X_train.reshape(-1, IMAGE_W * IMAGE_H * 3)\n",
        "  #decode y_train from one-hot encoding\n",
        "  y_train = np.argmax(y_train, axis=1) \n",
        "\n",
        "  counter = Counter(y_train)\n",
        "  key_max = max(counter, key=counter.get)\n",
        "  class_max = counter[key_max]\n",
        "  resx=[]\n",
        "  resy=[]\n",
        "\n",
        "  for i in range(start,n):\n",
        "      xclass, yclass = get_class(X_train, y_train, i)\n",
        "      if xclass.shape[0] == class_max:\n",
        "        continue\n",
        "      xclass_bdr, yclass_bdr = find_inner_border(xclass, yclass, X_train, y_train, i, n_neigh=k_neighbors)\n",
        "      n = class_max - xclass.shape[0]\n",
        "      xsamp, ysamp = G_SM(xclass_bdr,n,i, n_neigh=k_neighbors)\n",
        "      ysamp = np.array(ysamp)\n",
        "      resx.append(xsamp)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx = np.vstack(resx)\n",
        "  resy = np.hstack(resy)\n",
        "  X_train = np.vstack((resx,X_train))\n",
        "  y_train = np.hstack((resy,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIW7uLrYvZDv"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/PHD/Src/imbalanced-learn/imblearn/')\n",
        "sys.path.append('/content/drive/MyDrive/PHD/Src/imbalanced-learn/imblearn/over_sampling/')\n",
        "sys.path.append('/content/drive/MyDrive/PHD/Src/imbalanced-learn/imblearn/over_sampling/_smote/')\n",
        "from filter import BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Oversampling one class"
      ],
      "metadata": {
        "id": "IXruo6F58ryW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def G_SM(xclass,n_to_sample,cl, n_neigh = 6):\n",
        "  nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "  nn.fit(xclass)\n",
        "  dist, ind = nn.kneighbors(xclass)\n",
        "\n",
        "  # generating samples\n",
        "  base_indices = np.random.choice(list(range(len(xclass))),n_to_sample)\n",
        "  neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "  X_base = xclass[base_indices]\n",
        "  X_neighbor = xclass[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "  samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "          X_neighbor - X_base)\n",
        "\n",
        "  #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "  return samples, [cl]*n_to_sample\n",
        "\n",
        "def get_class(X, y, c):\n",
        "  xbeg = X[y == c]\n",
        "  ybeg = y[y == c]\n",
        "  return xbeg, ybeg"
      ],
      "metadata": {
        "id": "l4-XDjNaUryf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "n = 500\n",
        "k_neighbors = 5\n",
        "xclass, yclass = get_class(X_train.reshape(X_train.shape[0], -1), np.argmax(y_train, axis=1), 1)\n",
        "xsamp, ysamp = G_SM(xclass,n,i, n_neigh=k_neighbors)\n",
        "ysamp = np.array(ysamp)"
      ],
      "metadata": {
        "id": "Uc9y7zG8U3Fc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xsamp = xsamp.reshape(xsamp.shape[0],IMAGE_W, IMAGE_H,3)\n",
        "ysamp = ysamp.reshape(xsamp.shape[0],1)\n",
        "print(xsamp.shape, ysamp.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzp9j8PmWQHu",
        "outputId": "2a967189-d2e3-4f25-dba0-dc7c79e1ce59"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 128, 128, 3) (500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate((X_train, xsamp))\n",
        "y_train = np.concatenate((np.argmax(y_train, axis=1).reshape(-1,1), ysamp))\n",
        "y_train = to_categorical(y_train)"
      ],
      "metadata": {
        "id": "VPhyZsz6Ybpc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8eCte3qYIkB",
        "outputId": "a12d732c-fb1d-4c89-ff27-bbaef5e59e9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14577, 128, 128, 3) (14577, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "udkMXcZHXglm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b0573f-460a-48c1-cd08-f17a2bc51007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_borderline after smote on feature space_under70_128px.h5\n"
          ]
        }
      ],
      "source": [
        "exp_name=\"borderline after smote on feature space\"\n",
        "dataset_name=\"under70_128px\"\n",
        "train_under_frac = 0.7\n",
        "\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"best_model_fpath:\"+best_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qge6cnxQPnH6",
        "outputId": "9a8be3f4-766c-412d-af8e-9962ecd8394f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 128, 128, 3)\n",
            "(5321, 7)\n",
            "(193, 128, 128, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.read_pickle(path+\"isic2018_train_\"+dataset_name+\".pkl\")\n",
        "X_train = df1.loc[:, df1.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,IMAGE_W,IMAGE_H,3)\n",
        "y_train = df1.loc[:, df1.columns == 'y_train'].to_numpy()\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "df1 = pd.read_pickle(path+\"isic2018_val_\"+dataset_name+\".pkl\")\n",
        "X_val = df1.loc[:, df1.columns != 'y_val'].to_numpy()\n",
        "X_val = X_val.reshape(-1,IMAGE_W,IMAGE_H,3)\n",
        "y_val = df1.loc[:, df1.columns == 'y_val'].to_numpy()\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xArGWuciBt_-",
        "outputId": "44fa5d19-75b7-443c-9220-0c22b0f3d6c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17577, 128, 128, 3)\n",
            "(17577, 7)\n",
            "(193, 128, 128, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2511, 4: 2511, 2: 2511, 3: 2511, 0: 2511, 1: 2511, 6: 2511})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = SMOTE_Data(X_train, y_train, True, type = 'smote')\n",
        "#X_train, y_train = Borderline_SMOTE(X_train, y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V5PjA7jFhVU",
        "outputId": "38b5f38e-272e-483a-fa48-6186f4b7efcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9487, 2048)\n",
            "(9487, 7)\n",
            "Counter train data:  Counter({0: 1441, 5: 1341, 4: 1341, 2: 1341, 3: 1341, 1: 1341, 6: 1341})\n"
          ]
        }
      ],
      "source": [
        "n_new_samples = 100\n",
        "X_train = np.append(X_train_fm_ov, np.zeros(shape=(n_new_samples, 2048), dtype='object'), axis=0)\n",
        "y_train = np.argmax(y_train_ov, axis=1) \n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_train = np.append(y_train, np.zeros(shape=(n_new_samples, 1), dtype='object'))\n",
        "y_train = to_categorical(y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lFpLlexMUaM",
        "outputId": "137599b4-6ee6-49de-8cd9-13e82b8c2c89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9887, 2048)\n",
            "(9887, 7)\n",
            "Counter train data:  Counter({5: 1441, 4: 1441, 2: 1441, 1: 1441, 6: 1441, 3: 1341, 0: 1341})\n"
          ]
        }
      ],
      "source": [
        "# remove rows having all zeroes\n",
        "index = range(9387,9487)\n",
        "y_train = np.delete(y_train_ov, index, axis = 0)\n",
        "X_train = np.delete(X_train_fm_ov, index, axis = 0)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Z_nccu6QjB"
      },
      "outputs": [],
      "source": [
        "#path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "#df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "#df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "#df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "#df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "#df1.to_pickle(path+\"isic2018_train_under83.pkl\")\n",
        "#df2.to_pickle(path+\"isic2018_val.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vIygrW81Ln4z",
        "outputId": "cb2fcb2d-377c-43d8-d27c-0d1b5b770987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_smote after smote on input space_under70_128px.h5\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.9478 - accuracy: 0.6420 - balanced_acc: 0.6411\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.55300, saving model to /content/drive/MyDrive/PHD/Model/best_model_smote after smote on input space_under70_128px.h5\n",
            "274/274 [==============================] - 76s 229ms/step - loss: 0.9478 - accuracy: 0.6420 - balanced_acc: 0.6411 - val_loss: 0.8986 - val_accuracy: 0.6632 - val_balanced_acc: 0.5530 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.5812 - accuracy: 0.7773 - balanced_acc: 0.7777\n",
            "Epoch 2: val_balanced_acc did not improve from 0.55300\n",
            "274/274 [==============================] - 64s 228ms/step - loss: 0.5812 - accuracy: 0.7773 - balanced_acc: 0.7777 - val_loss: 0.8303 - val_accuracy: 0.6839 - val_balanced_acc: 0.4322 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.8276 - balanced_acc: 0.8283\n",
            "Epoch 3: val_balanced_acc did not improve from 0.55300\n",
            "274/274 [==============================] - 63s 229ms/step - loss: 0.4502 - accuracy: 0.8276 - balanced_acc: 0.8283 - val_loss: 0.7889 - val_accuracy: 0.7150 - val_balanced_acc: 0.4622 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.3978 - accuracy: 0.8585 - balanced_acc: 0.8598\n",
            "Epoch 4: val_balanced_acc did not improve from 0.55300\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.3978 - accuracy: 0.8585 - balanced_acc: 0.8598 - val_loss: 0.7074 - val_accuracy: 0.7306 - val_balanced_acc: 0.4452 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.3141 - accuracy: 0.8861 - balanced_acc: 0.8858\n",
            "Epoch 5: val_balanced_acc did not improve from 0.55300\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.3141 - accuracy: 0.8861 - balanced_acc: 0.8858 - val_loss: 0.7514 - val_accuracy: 0.7150 - val_balanced_acc: 0.4565 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.9042 - balanced_acc: 0.9049\n",
            "Epoch 6: val_balanced_acc did not improve from 0.55300\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.2670 - accuracy: 0.9042 - balanced_acc: 0.9049 - val_loss: 0.6861 - val_accuracy: 0.7461 - val_balanced_acc: 0.4597 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.9146 - balanced_acc: 0.9138\n",
            "Epoch 7: val_balanced_acc did not improve from 0.55300\n",
            "274/274 [==============================] - 63s 229ms/step - loss: 0.2341 - accuracy: 0.9146 - balanced_acc: 0.9138 - val_loss: 0.8284 - val_accuracy: 0.7358 - val_balanced_acc: 0.4696 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.1897 - accuracy: 0.9322 - balanced_acc: 0.9319\n",
            "Epoch 8: val_balanced_acc did not improve from 0.55300\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.1897 - accuracy: 0.9322 - balanced_acc: 0.9319 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_balanced_acc: 0.4537 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9378 - balanced_acc: 0.9372\n",
            "Epoch 9: val_balanced_acc improved from 0.55300 to 0.60405, saving model to /content/drive/MyDrive/PHD/Model/best_model_smote after smote on input space_under70_128px.h5\n",
            "274/274 [==============================] - 65s 236ms/step - loss: 0.1742 - accuracy: 0.9378 - balanced_acc: 0.9372 - val_loss: 0.7864 - val_accuracy: 0.7565 - val_balanced_acc: 0.6041 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.9362 - balanced_acc: 0.9362\n",
            "Epoch 10: val_balanced_acc did not improve from 0.60405\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.1822 - accuracy: 0.9362 - balanced_acc: 0.9362 - val_loss: 0.7485 - val_accuracy: 0.7202 - val_balanced_acc: 0.4674 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.1323 - accuracy: 0.9538 - balanced_acc: 0.9542\n",
            "Epoch 11: val_balanced_acc did not improve from 0.60405\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.1323 - accuracy: 0.9538 - balanced_acc: 0.9542 - val_loss: 0.6793 - val_accuracy: 0.8083 - val_balanced_acc: 0.4739 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.9592 - balanced_acc: 0.9594\n",
            "Epoch 12: val_balanced_acc did not improve from 0.60405\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.1128 - accuracy: 0.9592 - balanced_acc: 0.9594 - val_loss: 0.9407 - val_accuracy: 0.7358 - val_balanced_acc: 0.5584 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9589 - balanced_acc: 0.9586\n",
            "Epoch 13: val_balanced_acc did not improve from 0.60405\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.1172 - accuracy: 0.9589 - balanced_acc: 0.9586 - val_loss: 0.8543 - val_accuracy: 0.7513 - val_balanced_acc: 0.4221 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9656 - balanced_acc: 0.9653\n",
            "Epoch 14: val_balanced_acc improved from 0.60405 to 0.60462, saving model to /content/drive/MyDrive/PHD/Model/best_model_smote after smote on input space_under70_128px.h5\n",
            "274/274 [==============================] - 64s 235ms/step - loss: 0.0937 - accuracy: 0.9656 - balanced_acc: 0.9653 - val_loss: 0.9485 - val_accuracy: 0.7409 - val_balanced_acc: 0.6046 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9672 - balanced_acc: 0.9672\n",
            "Epoch 15: val_balanced_acc improved from 0.60462 to 0.60492, saving model to /content/drive/MyDrive/PHD/Model/best_model_smote after smote on input space_under70_128px.h5\n",
            "274/274 [==============================] - 65s 236ms/step - loss: 0.0847 - accuracy: 0.9672 - balanced_acc: 0.9672 - val_loss: 0.8851 - val_accuracy: 0.7617 - val_balanced_acc: 0.6049 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9608 - balanced_acc: 0.9619\n",
            "Epoch 16: val_balanced_acc did not improve from 0.60492\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.1119 - accuracy: 0.9608 - balanced_acc: 0.9619 - val_loss: 0.9073 - val_accuracy: 0.7461 - val_balanced_acc: 0.4583 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9680 - balanced_acc: 0.9673\n",
            "Epoch 17: val_balanced_acc did not improve from 0.60492\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0891 - accuracy: 0.9680 - balanced_acc: 0.9673 - val_loss: 1.0749 - val_accuracy: 0.7461 - val_balanced_acc: 0.4664 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9697 - balanced_acc: 0.9695\n",
            "Epoch 18: val_balanced_acc did not improve from 0.60492\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0728 - accuracy: 0.9697 - balanced_acc: 0.9695 - val_loss: 0.9198 - val_accuracy: 0.7824 - val_balanced_acc: 0.4904 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9697 - balanced_acc: 0.9692\n",
            "Epoch 19: val_balanced_acc did not improve from 0.60492\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0714 - accuracy: 0.9697 - balanced_acc: 0.9692 - val_loss: 0.9360 - val_accuracy: 0.7668 - val_balanced_acc: 0.4276 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.9707 - balanced_acc: 0.9706\n",
            "Epoch 20: val_balanced_acc did not improve from 0.60492\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0679 - accuracy: 0.9707 - balanced_acc: 0.9706 - val_loss: 1.0625 - val_accuracy: 0.7565 - val_balanced_acc: 0.4423 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9706 - balanced_acc: 0.9714\n",
            "Epoch 21: val_balanced_acc did not improve from 0.60492\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0684 - accuracy: 0.9706 - balanced_acc: 0.9714 - val_loss: 0.9930 - val_accuracy: 0.7513 - val_balanced_acc: 0.5402 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9722 - balanced_acc: 0.9714\n",
            "Epoch 22: val_balanced_acc improved from 0.60492 to 0.61787, saving model to /content/drive/MyDrive/PHD/Model/best_model_smote after smote on input space_under70_128px.h5\n",
            "274/274 [==============================] - 64s 235ms/step - loss: 0.0651 - accuracy: 0.9722 - balanced_acc: 0.9714 - val_loss: 0.9719 - val_accuracy: 0.7876 - val_balanced_acc: 0.6179 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9713 - balanced_acc: 0.9717\n",
            "Epoch 23: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0630 - accuracy: 0.9713 - balanced_acc: 0.9717 - val_loss: 1.0744 - val_accuracy: 0.7772 - val_balanced_acc: 0.5578 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9720 - balanced_acc: 0.9725\n",
            "Epoch 24: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0624 - accuracy: 0.9720 - balanced_acc: 0.9725 - val_loss: 1.0121 - val_accuracy: 0.7927 - val_balanced_acc: 0.5769 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9720 - balanced_acc: 0.9717\n",
            "Epoch 25: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0629 - accuracy: 0.9720 - balanced_acc: 0.9717 - val_loss: 1.0703 - val_accuracy: 0.7668 - val_balanced_acc: 0.4281 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9741 - balanced_acc: 0.9741\n",
            "Epoch 26: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0581 - accuracy: 0.9741 - balanced_acc: 0.9741 - val_loss: 1.1444 - val_accuracy: 0.7772 - val_balanced_acc: 0.4367 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9733 - balanced_acc: 0.9738\n",
            "Epoch 27: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0596 - accuracy: 0.9733 - balanced_acc: 0.9738 - val_loss: 1.1277 - val_accuracy: 0.7617 - val_balanced_acc: 0.4247 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9734 - balanced_acc: 0.9726\n",
            "Epoch 28: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0580 - accuracy: 0.9734 - balanced_acc: 0.9726 - val_loss: 1.0934 - val_accuracy: 0.7617 - val_balanced_acc: 0.4308 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9729 - balanced_acc: 0.9729\n",
            "Epoch 29: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0590 - accuracy: 0.9729 - balanced_acc: 0.9729 - val_loss: 1.0462 - val_accuracy: 0.7824 - val_balanced_acc: 0.5571 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9542 - balanced_acc: 0.9548\n",
            "Epoch 30: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.1311 - accuracy: 0.9542 - balanced_acc: 0.9548 - val_loss: 0.8539 - val_accuracy: 0.7617 - val_balanced_acc: 0.4944 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9740 - balanced_acc: 0.9741\n",
            "Epoch 31: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0633 - accuracy: 0.9740 - balanced_acc: 0.9741 - val_loss: 1.0573 - val_accuracy: 0.7513 - val_balanced_acc: 0.4414 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9754 - balanced_acc: 0.9754\n",
            "Epoch 32: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0551 - accuracy: 0.9754 - balanced_acc: 0.9754 - val_loss: 0.9604 - val_accuracy: 0.7772 - val_balanced_acc: 0.4643 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9755 - balanced_acc: 0.9746\n",
            "Epoch 33: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0549 - accuracy: 0.9755 - balanced_acc: 0.9746 - val_loss: 1.0421 - val_accuracy: 0.7720 - val_balanced_acc: 0.4831 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9741 - balanced_acc: 0.9745\n",
            "Epoch 34: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0553 - accuracy: 0.9741 - balanced_acc: 0.9745 - val_loss: 1.0688 - val_accuracy: 0.7668 - val_balanced_acc: 0.5885 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.9218 - balanced_acc: 0.9232\n",
            "Epoch 35: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.2275 - accuracy: 0.9218 - balanced_acc: 0.9232 - val_loss: 0.7212 - val_accuracy: 0.7824 - val_balanced_acc: 0.4891 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9684 - balanced_acc: 0.9688\n",
            "Epoch 36: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0767 - accuracy: 0.9684 - balanced_acc: 0.9688 - val_loss: 0.9237 - val_accuracy: 0.7565 - val_balanced_acc: 0.4727 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9737 - balanced_acc: 0.9734\n",
            "Epoch 37: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0574 - accuracy: 0.9737 - balanced_acc: 0.9734 - val_loss: 1.0095 - val_accuracy: 0.7927 - val_balanced_acc: 0.4909 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9756 - balanced_acc: 0.9759\n",
            "Epoch 38: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0539 - accuracy: 0.9756 - balanced_acc: 0.9759 - val_loss: 1.0573 - val_accuracy: 0.7772 - val_balanced_acc: 0.4771 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9758 - balanced_acc: 0.9756\n",
            "Epoch 39: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0528 - accuracy: 0.9758 - balanced_acc: 0.9756 - val_loss: 1.0959 - val_accuracy: 0.7824 - val_balanced_acc: 0.6027 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9769 - balanced_acc: 0.9770\n",
            "Epoch 40: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0523 - accuracy: 0.9769 - balanced_acc: 0.9770 - val_loss: 1.0108 - val_accuracy: 0.7979 - val_balanced_acc: 0.6125 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9750 - balanced_acc: 0.9756\n",
            "Epoch 41: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0525 - accuracy: 0.9750 - balanced_acc: 0.9756 - val_loss: 1.2024 - val_accuracy: 0.7565 - val_balanced_acc: 0.6071 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9737 - balanced_acc: 0.9745\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 42: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0533 - accuracy: 0.9737 - balanced_acc: 0.9745 - val_loss: 1.0176 - val_accuracy: 0.7824 - val_balanced_acc: 0.4887 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9815 - balanced_acc: 0.9812\n",
            "Epoch 43: val_balanced_acc did not improve from 0.61787\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0416 - accuracy: 0.9815 - balanced_acc: 0.9812 - val_loss: 1.0973 - val_accuracy: 0.7876 - val_balanced_acc: 0.6064 - lr: 5.0000e-04\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9809 - balanced_acc: 0.9811\n",
            "Epoch 44: val_balanced_acc improved from 0.61787 to 0.62571, saving model to /content/drive/MyDrive/PHD/Model/best_model_smote after smote on input space_under70_128px.h5\n",
            "274/274 [==============================] - 65s 236ms/step - loss: 0.0413 - accuracy: 0.9809 - balanced_acc: 0.9811 - val_loss: 1.1326 - val_accuracy: 0.8083 - val_balanced_acc: 0.6257 - lr: 5.0000e-04\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9805 - balanced_acc: 0.9804\n",
            "Epoch 45: val_balanced_acc did not improve from 0.62571\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0411 - accuracy: 0.9805 - balanced_acc: 0.9804 - val_loss: 1.1530 - val_accuracy: 0.7720 - val_balanced_acc: 0.4876 - lr: 5.0000e-04\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9810 - balanced_acc: 0.9813\n",
            "Epoch 46: val_balanced_acc did not improve from 0.62571\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0400 - accuracy: 0.9810 - balanced_acc: 0.9813 - val_loss: 1.1829 - val_accuracy: 0.7668 - val_balanced_acc: 0.4657 - lr: 5.0000e-04\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9813 - balanced_acc: 0.9809\n",
            "Epoch 47: val_balanced_acc did not improve from 0.62571\n",
            "274/274 [==============================] - 63s 231ms/step - loss: 0.0394 - accuracy: 0.9813 - balanced_acc: 0.9809 - val_loss: 1.1758 - val_accuracy: 0.7979 - val_balanced_acc: 0.4963 - lr: 5.0000e-04\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9799 - balanced_acc: 0.9797\n",
            "Epoch 48: val_balanced_acc did not improve from 0.62571\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0411 - accuracy: 0.9799 - balanced_acc: 0.9797 - val_loss: 1.1416 - val_accuracy: 0.7927 - val_balanced_acc: 0.4868 - lr: 5.0000e-04\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9809 - balanced_acc: 0.9811\n",
            "Epoch 49: val_balanced_acc did not improve from 0.62571\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0396 - accuracy: 0.9809 - balanced_acc: 0.9811 - val_loss: 1.1791 - val_accuracy: 0.7772 - val_balanced_acc: 0.4732 - lr: 5.0000e-04\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9805 - balanced_acc: 0.9807\n",
            "Epoch 50: val_balanced_acc did not improve from 0.62571\n",
            "274/274 [==============================] - 63s 230ms/step - loss: 0.0399 - accuracy: 0.9805 - balanced_acc: 0.9807 - val_loss: 1.2018 - val_accuracy: 0.7772 - val_balanced_acc: 0.4773 - lr: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# define model\n",
        "model = define_model_resnet()\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"best_model_fpath:\"+best_model_fpath)\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=40,monitor='val_balanced_acc')\n",
        "#model.summary()\n",
        "hst = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    #callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n",
        "                    callbacks=[learning_rate_reduction,mc])\n",
        "# learning curves\n",
        "summarize_diagnostics(hst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPz8NH1Oylv9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "#last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+'no_smote'+'_'+dataset_name+'.h5'\n",
        "model.save(last_model_fpath)\n",
        "print(\"model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXnW3lmCgln3"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icgjmi-4UIT-"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS3ewyxO_anU",
        "outputId": "2d2165ec-e7aa-47e0-b5d3-ff9d4bc65c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 7s 37ms/step\n",
            "7/7 [==============================] - 0s 36ms/step\n",
            "accuracy on training 1.0\n",
            "balanced accuracy on training 1.0\n",
            "accuracy on validation 0.8134715025906736\n",
            "balanced accuracy on validation 0.7570508469463173\n",
            "Score on val data:  (0.7747822450214207, 0.7570508469463173, 0.7498695315313916, None)\n"
          ]
        }
      ],
      "source": [
        "#last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_smote_under70_128px.h5'\n",
        "#last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+'no_smote'+'_'+dataset_name+'.h5'\n",
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "W3IyWjdGG4Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b85d26-1ebb-4e5c-9734-d35f53e3c032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_fpath:  /content/drive/MyDrive/PHD/Model/best_model_no_smote_under70_128px.h5\n",
            "167/167 [==============================] - 7s 37ms/step\n",
            "7/7 [==============================] - 0s 36ms/step\n",
            "accuracy on training 0.992858485247134\n",
            "balanced accuracy on training 0.99055145365288\n",
            "accuracy on validation 0.8652849740932642\n",
            "balanced accuracy on validation 0.80326862452298\n",
            "Score on val data:  (0.8062119584675976, 0.80326862452298, 0.7697449361934251, None)\n"
          ]
        }
      ],
      "source": [
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+'no_smote'+'_'+dataset_name+'.h5'\n",
        "#best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_smote on input space_under70_128px.h5'\n",
        "print('best_model_fpath: ',best_model_fpath)\n",
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(exp_name,dataset_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaTGEWQ7uDAx",
        "outputId": "d0a91595-4ef8-4ffd-d6a8-e6f35796966c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "smote after smote on input space under70_128px\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRWiTnO0MGh"
      },
      "source": [
        "#Cut-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGnCoIdLyDHS"
      },
      "outputs": [],
      "source": [
        "df_val_pred = pd.DataFrame(y_val_pred, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdyCbloQyWTC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "2434e5f4-d6f2-45ea-8afd-7d8ec66b0d45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          AKIEC           BCC           BKL            DF           MEL  \\\n",
              "0  3.090921e-07  9.996200e-01  2.427639e-04  6.437593e-05  1.916536e-05   \n",
              "1  1.375006e-15  1.271707e-15  7.886792e-10  3.873745e-13  6.200786e-07   \n",
              "2  2.292977e-02  9.769607e-01  3.134560e-05  3.750155e-06  1.027365e-08   \n",
              "3  3.805227e-16  1.073426e-13  1.566999e-07  2.658983e-14  4.196105e-05   \n",
              "4  2.687866e-13  2.825541e-15  1.501939e-08  2.123309e-14  5.977655e-08   \n",
              "\n",
              "             NV          VASC  0.0  0.025  0.05  0.075  0.1  0.125  0.15  \\\n",
              "0  5.326564e-05  1.437628e-07    1      0     0      0    0      0     0   \n",
              "1  9.999994e-01  6.723950e-14    1      0     0      0    0      0     0   \n",
              "2  5.761424e-09  7.435224e-05    1      0     0      0    0      0     0   \n",
              "3  9.999579e-01  1.634144e-08    1      0     0      0    0      0     0   \n",
              "4  9.999999e-01  1.584354e-11    1      0     0      0    0      0     0   \n",
              "\n",
              "   0.175  0.2  0.225  0.25  \n",
              "0      0    0      0     0  \n",
              "1      0    0      0     0  \n",
              "2      0    0      0     0  \n",
              "3      0    0      0     0  \n",
              "4      0    0      0     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b7dda8c-99a5-44cb-bbe2-70b86e21d791\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AKIEC</th>\n",
              "      <th>BCC</th>\n",
              "      <th>BKL</th>\n",
              "      <th>DF</th>\n",
              "      <th>MEL</th>\n",
              "      <th>NV</th>\n",
              "      <th>VASC</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.025</th>\n",
              "      <th>0.05</th>\n",
              "      <th>0.075</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.125</th>\n",
              "      <th>0.15</th>\n",
              "      <th>0.175</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.225</th>\n",
              "      <th>0.25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.090921e-07</td>\n",
              "      <td>9.996200e-01</td>\n",
              "      <td>2.427639e-04</td>\n",
              "      <td>6.437593e-05</td>\n",
              "      <td>1.916536e-05</td>\n",
              "      <td>5.326564e-05</td>\n",
              "      <td>1.437628e-07</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.375006e-15</td>\n",
              "      <td>1.271707e-15</td>\n",
              "      <td>7.886792e-10</td>\n",
              "      <td>3.873745e-13</td>\n",
              "      <td>6.200786e-07</td>\n",
              "      <td>9.999994e-01</td>\n",
              "      <td>6.723950e-14</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.292977e-02</td>\n",
              "      <td>9.769607e-01</td>\n",
              "      <td>3.134560e-05</td>\n",
              "      <td>3.750155e-06</td>\n",
              "      <td>1.027365e-08</td>\n",
              "      <td>5.761424e-09</td>\n",
              "      <td>7.435224e-05</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.805227e-16</td>\n",
              "      <td>1.073426e-13</td>\n",
              "      <td>1.566999e-07</td>\n",
              "      <td>2.658983e-14</td>\n",
              "      <td>4.196105e-05</td>\n",
              "      <td>9.999579e-01</td>\n",
              "      <td>1.634144e-08</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.687866e-13</td>\n",
              "      <td>2.825541e-15</td>\n",
              "      <td>1.501939e-08</td>\n",
              "      <td>2.123309e-14</td>\n",
              "      <td>5.977655e-08</td>\n",
              "      <td>9.999999e-01</td>\n",
              "      <td>1.584354e-11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b7dda8c-99a5-44cb-bbe2-70b86e21d791')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b7dda8c-99a5-44cb-bbe2-70b86e21d791 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b7dda8c-99a5-44cb-bbe2-70b86e21d791');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "numbers = [float(x)/40 for x in range(11)]\n",
        "for i in numbers:\n",
        "    df_val_pred[i]= df_val_pred.MEL.map(lambda x: 1 if x > i else 0)\n",
        "df_val_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SQsRx73kgk"
      },
      "outputs": [],
      "source": [
        "y_val_true= [1 if x == 4 else 0 for x in np.argmax(y_val, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcUISWFi0J05"
      },
      "outputs": [],
      "source": [
        "#num = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\n",
        "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity'])\n",
        "for i in numbers:\n",
        "    cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,Accuracy,Sensitivity,Specificity]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W31LSzov1tCt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "11b69ad8-6b32-48dd-ea3a-48a678d7264e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cutoff_df[['Accuracy','Sensitivity','Specificity']].plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6CIKT94Jqye"
      },
      "outputs": [],
      "source": [
        "i = 0.025\n",
        "cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "total1=sum(sum(cm1))\n",
        "Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U2tkFebL_VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30286149-e8ed-462a-8723-85b0eb1f057b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8082901554404145\n",
            "Sensitivity:  0.8571428571428571\n",
            "Specificity:  0.8023255813953488\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: ', Accuracy)\n",
        "print('Sensitivity: ', Sensitivity)\n",
        "print('Specificity: ', Specificity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkPOFLehOmFg"
      },
      "outputs": [],
      "source": [
        "#change melanoma flag back to 4\n",
        "df_val_pred[df_val_pred[i] == 1] = 4\n",
        "#decode one-hot y_val_pred while use cut-off melanoma data\n",
        "condition = df_val_pred[i] == 4\n",
        "y_val_pred2 = np.where(condition, df_val_pred[i], np.argmax(y_val_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOVl6dWlTDLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34cd0f8c-f655-414b-a73a-e344ff46a1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7150259067357513\n",
            "Balanced accuracy:  0.7596124259016246\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: ',accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))\n",
        "print('Balanced accuracy: ',balanced_accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "mqvYutTKRhR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d50f61d0-013b-4c1c-ff68-ada77011ea24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  4   1   3   0   0   0   0]\n",
            " [  1  11   1   1   0   1   0]\n",
            " [  0   1  17   0   4   0   0]\n",
            " [  0   0   0   1   0   0   0]\n",
            " [  0   0   3   0  16   2   0]\n",
            " [  0   2   5   1   7 108   0]\n",
            " [  0   1   0   0   0   0   2]]\n"
          ]
        }
      ],
      "source": [
        "#Get the confusion matrix\n",
        "#cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), y_val_pred2)#FOR CUT-OFF\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1))\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "gVtvW3YeaLlC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "b6147edf-60d2-4616-8836-c3a2a8db8cf2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(exp_name, dataset_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJrJQC8_T7Vf",
        "outputId": "80a22255-b6ab-4f08-8aef-888e423fb571"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "borderline after smote on feature space under70_128px\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey-1yjWGeKs7"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "#labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "#f = plt.figure(figsize=(15, 6))\n",
        "#s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "#s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN98sOWPyT3P",
        "outputId": "d762e235-ef79-45e5-91b3-700932bd579b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1512, 128, 128, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "df_test = pd.read_pickle(path+\"isic2018_test_\"+dataset_name+\".pkl\")\n",
        "X_test = df_test.loc[:, df_test.columns != 'y_train'].to_numpy()\n",
        "X_test = X_test.reshape(-1,IMAGE_W,IMAGE_H,3)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "#ONLY FOR LOADING DATASET FROM CSV\n",
        "df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "df_test['FilePaths'] = dir_test + df_test['image']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "df_test['image_px'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60LYAT7VsNOZ",
        "outputId": "d5e0ecb3-457f-42ef-b7f9-978671db89d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.asarray(df_test['image_px'].tolist())\n",
        "print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnnIIwC4cHE"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "X_test = preprocess_image_input(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC17MArBxhSW"
      },
      "outputs": [],
      "source": [
        "df3 = pd.DataFrame(X_test.reshape(X_test.shape[0],-1))\n",
        "df3.to_pickle(path+\"isic2018_test_\"+dataset_name+\".pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeDTXdaMLmyU",
        "outputId": "a6ea64da-79f0-424f-f913-5b0bd6c66170"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1512, 2048)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#FOR MAKING FEATURE SPACE DATA\n",
        "X_test = model1.predict(X_test)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIX0AmEFNv3Y",
        "outputId": "94f97d01-cfcd-4060-e030-791de041abea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 2s 34ms/step\n",
            "Y_pred2 (1512, 7)\n"
          ]
        }
      ],
      "source": [
        "# predicting\n",
        "#CHANGE THE MODEL IF NECESSARY\n",
        "Y_pred2 = best_model.predict(X_test)\n",
        "#Y_pred2 = model2.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]\n",
        "df_pred.set_index(\"image\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ynyd8PjT589"
      },
      "outputs": [],
      "source": [
        "#update MEL data using cut-off value\n",
        "df_pred.MEL[df_pred.MEL > i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRdONoQVMq0"
      },
      "outputs": [],
      "source": [
        "df_pred.loc[df_pred.MEL > i, ['NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4Iv_3s4z0R9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c4bcab80-dd0c-4e50-c3de-77b4d3791ff8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       MEL        NV           BCC         AKIEC  \\\n",
              "image                                                              \n",
              "ISIC_0034524  3.026130e-11  1.000000  6.653910e-11  2.585303e-11   \n",
              "ISIC_0034525  8.898649e-07  0.999993  3.913597e-07  1.369540e-07   \n",
              "ISIC_0034526  2.697274e-03  0.000552  1.982842e-08  1.716201e-07   \n",
              "ISIC_0034527  6.416706e-03  0.993283  1.623954e-08  4.608250e-08   \n",
              "ISIC_0034528  1.387109e-06  0.921095  4.336646e-09  6.083735e-10   \n",
              "\n",
              "                       BKL            DF          VASC  \n",
              "image                                                   \n",
              "ISIC_0034524  9.672514e-09  4.063111e-11  7.206132e-10  \n",
              "ISIC_0034525  4.857814e-10  5.819595e-06  5.586446e-11  \n",
              "ISIC_0034526  9.967508e-01  7.306222e-09  2.069174e-11  \n",
              "ISIC_0034527  3.000382e-04  8.077440e-10  3.280298e-11  \n",
              "ISIC_0034528  7.890303e-02  1.081984e-08  2.983435e-14  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3904ec89-7c91-4429-8150-533161c8d0f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MEL</th>\n",
              "      <th>NV</th>\n",
              "      <th>BCC</th>\n",
              "      <th>AKIEC</th>\n",
              "      <th>BKL</th>\n",
              "      <th>DF</th>\n",
              "      <th>VASC</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ISIC_0034524</th>\n",
              "      <td>3.026130e-11</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.653910e-11</td>\n",
              "      <td>2.585303e-11</td>\n",
              "      <td>9.672514e-09</td>\n",
              "      <td>4.063111e-11</td>\n",
              "      <td>7.206132e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034525</th>\n",
              "      <td>8.898649e-07</td>\n",
              "      <td>0.999993</td>\n",
              "      <td>3.913597e-07</td>\n",
              "      <td>1.369540e-07</td>\n",
              "      <td>4.857814e-10</td>\n",
              "      <td>5.819595e-06</td>\n",
              "      <td>5.586446e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034526</th>\n",
              "      <td>2.697274e-03</td>\n",
              "      <td>0.000552</td>\n",
              "      <td>1.982842e-08</td>\n",
              "      <td>1.716201e-07</td>\n",
              "      <td>9.967508e-01</td>\n",
              "      <td>7.306222e-09</td>\n",
              "      <td>2.069174e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034527</th>\n",
              "      <td>6.416706e-03</td>\n",
              "      <td>0.993283</td>\n",
              "      <td>1.623954e-08</td>\n",
              "      <td>4.608250e-08</td>\n",
              "      <td>3.000382e-04</td>\n",
              "      <td>8.077440e-10</td>\n",
              "      <td>3.280298e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034528</th>\n",
              "      <td>1.387109e-06</td>\n",
              "      <td>0.921095</td>\n",
              "      <td>4.336646e-09</td>\n",
              "      <td>6.083735e-10</td>\n",
              "      <td>7.890303e-02</td>\n",
              "      <td>1.081984e-08</td>\n",
              "      <td>2.983435e-14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3904ec89-7c91-4429-8150-533161c8d0f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3904ec89-7c91-4429-8150-533161c8d0f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3904ec89-7c91-4429-8150-533161c8d0f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "df_pred.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnjc3RJ0e4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd8c7bf-b96e-4b27-a5f0-5d157dbb5308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response saved!\n"
          ]
        }
      ],
      "source": [
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_'+exp_name+'_'+dataset_name+'.csv')\n",
        "print(\"response saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(exp_name, dataset_name, \"result: 0.575\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt1C_FXiR3Ip",
        "outputId": "803c98f6-e1d9-460f-f863-4988ec8299c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deep smote under70_128px result: 0.575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswA0co2y1wl"
      },
      "source": [
        "#Exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnqJYIONy34l"
      },
      "outputs": [],
      "source": [
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "base_model = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "x = base_model(input_tensor, training=False)\n",
        "x = Attention(2048,2048,7,8)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "res50 = Model(inputs=input_tensor, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcn8hQg3J8yP"
      },
      "outputs": [],
      "source": [
        "#Train i-last layer\n",
        "# summarize feature map shapes\n",
        "for i in range(len(model.layers)):\n",
        "    layer = model.layers[i]\n",
        "    # summarize output shape\n",
        "    print(i, layer.name, layer.output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA7Af2Y73FUv"
      },
      "outputs": [],
      "source": [
        "X_train = res50.predict(X_train)\n",
        "X_val = res50.predict(X_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krJiAb1m3QNf"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = SMOTE_Data2(X_train, y_train, True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfcFpsBwM0d4"
      },
      "source": [
        "#Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "C_s6OIGKM26a",
        "outputId": "371bd24a-4bf9-491a-e0ec-78b7eb06e6d9"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ff488085aaa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Image preprocessing layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tk\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,AveragePooling2D,BatchNormalization,Add,ZeroPadding2D,Flatten,Dense,Input,LeakyReLU,Softmax,ReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class Attention(tk.layers.Layer):\n",
        "    \n",
        "    def __init__(self,input_channels,output_channel,kernel_size,groups):\n",
        "        super().__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channel = output_channel    \n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = 1\n",
        "        self.groups = groups\n",
        "\n",
        "        assert output_channel % groups == 0\n",
        "        \n",
        "        self.rel_h = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,kernel_size,1,output_channel//2),stddev = 0.1)) \n",
        "        #output_channels//2 is the number of channels on which the relative position will be considered,1 denotes the number of those filters and the one after that too and (kernel_size,1) denotes the size of that filter\n",
        "        self.rel_w = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,1,kernel_size,output_channel//2),stddev = 0.1)) \n",
        "\n",
        "        self.key_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.query_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.value_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "\n",
        "    def call(self,x):\n",
        "        \n",
        "        batch,height,width,channels = x.shape\n",
        "        x_padded = ZeroPadding2D(padding=(self.kernel_size//2,self.kernel_size//2))(x)\n",
        "        query = self.query_weights(x)\n",
        "        value = self.value_weights(x_padded)\n",
        "        key = self.key_weights(x_padded)\n",
        "        #key,query and value will have the shape of (batch,height,width,depth)\n",
        "        keys = tf.image.extract_patches(images = key,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        value = tf.image.extract_patches(images = value,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        no_of_kernels = key.shape[-2] - self.kernel_size + 1\n",
        "        keys = tf.reshape(keys,shape = (-1,no_of_kernels, no_of_kernels,self.kernel_size,self.kernel_size,self.output_channel))\n",
        "        key_split_h,key_split_w = tf.split(keys,num_or_size_splits = 2,axis = -1)\n",
        "        key_with_rel = tk.layers.concatenate([key_split_h + self.rel_h,key_split_w + self.rel_w],axis = -1) \n",
        "        \n",
        "        #reshaping the query and key\n",
        "        key_with_rel = tf.reshape(key_with_rel,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        query  = tf.reshape(query,(-1,self.groups,no_of_kernels,no_of_kernels,1,self.output_channel//self.groups))        \n",
        "        value = tf.reshape(value,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        \n",
        "        #multiplication  of key and query\n",
        "        #assert key_with_rel.shape == query.shape        \n",
        "        key_prod_query = query*key_with_rel\n",
        "        \n",
        "        # Now the function is passed through the softmax and is multiplied with the values\n",
        "        s = Softmax(axis = -2)(key_prod_query)\n",
        "        y = tf.einsum('bnchwk,bnchwk->bnchk',s,value)\n",
        "        y = tf.reshape(y,(-1,height,width,self.output_channel))\n",
        "        return y\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            \"input_channels\": self.input_channels, \n",
        "            \"output_channel\": self.output_channel, \n",
        "            \"kernel_size\": self.kernel_size, \n",
        "            \"stride\": self.stride, \n",
        "            \"groups\": self.groups, \n",
        "            \"rel_h\": self.rel_h, \n",
        "            \"rel_w\": self.rel_w, \n",
        "            \"key_weights\": self.key_weights, \n",
        "            \"query_weights\": self.query_weights, \n",
        "            \"value_weights\": self.value_weights\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE8Ziq-BlEP4"
      },
      "source": [
        "#Oversampling on feature map level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wqfEP5L9BgcF"
      },
      "outputs": [],
      "source": [
        "#CHANGE THIS\n",
        "model = best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm05Zet_B5am",
        "outputId": "72aa8ed0-0b5c-41fd-e236-47fccdb29166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1 [(None, 128, 128, 3)] True\n",
            "1 resnet50 (None, 4, 4, 2048) True\n",
            "2 global_average_pooling2d (None, 2048) True\n",
            "3 flatten (None, 2048) True\n",
            "4 dense (None, 1024) True\n",
            "5 dense_1 (None, 512) True\n",
            "6 dense_2 (None, 7) True\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(model.layers)):\n",
        "  layer = model.layers[i]\n",
        "  print(i, layer.name, layer.output_shape, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KqeSic6NmLsR"
      },
      "outputs": [],
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "end = 2\n",
        "model1 = Model(inputs=model.inputs, outputs=model.layers[end].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVHYG9Rwm28i",
        "outputId": "cc6ad38f-86a6-4b22-bd4f-d440e7435da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 7s 35ms/step\n",
            "7/7 [==============================] - 0s 34ms/step\n",
            "(5321, 2048)\n",
            "(5321, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "# get feature map for first hidden layer\n",
        "X_train = model1.predict(X_train)\n",
        "X_val = model1.predict(X_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19hK7aQNeAQo",
        "outputId": "f747b20c-4c37-498e-8c3f-0333d819ad40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/imblearn/utils/_validation.py:300: UserWarning: After over-sampling, the number of samples (2500) in class 0 will be larger than the number of samples in the majority class (class #0 -> 2011)\n",
            "  f\"After over-sampling, the number of samples ({n_samples})\"\n",
            "/usr/local/lib/python3.7/dist-packages/imblearn/utils/_validation.py:300: UserWarning: After over-sampling, the number of samples (2500) in class 1 will be larger than the number of samples in the majority class (class #0 -> 2011)\n",
            "  f\"After over-sampling, the number of samples ({n_samples})\"\n",
            "/usr/local/lib/python3.7/dist-packages/imblearn/utils/_validation.py:300: UserWarning: After over-sampling, the number of samples (2500) in class 2 will be larger than the number of samples in the majority class (class #0 -> 2011)\n",
            "  f\"After over-sampling, the number of samples ({n_samples})\"\n",
            "/usr/local/lib/python3.7/dist-packages/imblearn/utils/_validation.py:300: UserWarning: After over-sampling, the number of samples (2500) in class 3 will be larger than the number of samples in the majority class (class #0 -> 2011)\n",
            "  f\"After over-sampling, the number of samples ({n_samples})\"\n",
            "/usr/local/lib/python3.7/dist-packages/imblearn/utils/_validation.py:300: UserWarning: After over-sampling, the number of samples (2500) in class 4 will be larger than the number of samples in the majority class (class #0 -> 2011)\n",
            "  f\"After over-sampling, the number of samples ({n_samples})\"\n",
            "/usr/local/lib/python3.7/dist-packages/imblearn/utils/_validation.py:300: UserWarning: After over-sampling, the number of samples (2500) in class 5 will be larger than the number of samples in the majority class (class #0 -> 2011)\n",
            "  f\"After over-sampling, the number of samples ({n_samples})\"\n",
            "/usr/local/lib/python3.7/dist-packages/imblearn/utils/_validation.py:300: UserWarning: After over-sampling, the number of samples (2500) in class 6 will be larger than the number of samples in the majority class (class #0 -> 2011)\n",
            "  f\"After over-sampling, the number of samples ({n_samples})\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16522, 2048)\n",
            "(16522, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2500, 4: 2500, 2: 2500, 0: 2500, 1: 2500, 3: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = SMOTE_Data2(X_train, y_train, True, 5, type=\"borderline\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "5qP4iyYcnAYa"
      },
      "outputs": [],
      "source": [
        "model2 = Model(inputs=model.layers[end+1].input, outputs=model.layers[len(model.layers)-1].output)\n",
        "#model2 = define_base_model(arch = 'dense')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzdjs0WbvDB0",
        "outputId": "ce3d81a3-a99b-4dae-8792-2ed0a66fc131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_borderline after smote on feature space_under70_128px.h5\n",
            "last_model_fpath:/content/drive/MyDrive/PHD/Model/last_model_borderline after smote on feature space_under70_128px.h5\n",
            "Epoch 1/50\n",
            "246/258 [===========================>..] - ETA: 0s - loss: 0.0482 - accuracy: 0.9963 - balanced_acc: 0.9965\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.49010, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline after smote on feature space_under70_128px.h5\n",
            "258/258 [==============================] - 2s 5ms/step - loss: 0.0480 - accuracy: 0.9963 - balanced_acc: 0.9966 - val_loss: 0.5737 - val_accuracy: 0.8238 - val_balanced_acc: 0.4901 - lr: 5.0000e-04\n",
            "Epoch 2/50\n",
            "256/258 [============================>.] - ETA: 0s - loss: 0.0416 - accuracy: 0.9971 - balanced_acc: 0.9961\n",
            "Epoch 2: val_balanced_acc did not improve from 0.49010\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9971 - balanced_acc: 0.9961 - val_loss: 0.5768 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 3/50\n",
            "247/258 [===========================>..] - ETA: 0s - loss: 0.0379 - accuracy: 0.9977 - balanced_acc: 0.9972\n",
            "Epoch 3: val_balanced_acc did not improve from 0.49010\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0379 - accuracy: 0.9978 - balanced_acc: 0.9973 - val_loss: 0.5682 - val_accuracy: 0.8238 - val_balanced_acc: 0.4870 - lr: 5.0000e-04\n",
            "Epoch 4/50\n",
            "244/258 [===========================>..] - ETA: 0s - loss: 0.0353 - accuracy: 0.9981 - balanced_acc: 0.9982\n",
            "Epoch 4: val_balanced_acc did not improve from 0.49010\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9981 - balanced_acc: 0.9982 - val_loss: 0.5832 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 5/50\n",
            "246/258 [===========================>..] - ETA: 0s - loss: 0.0331 - accuracy: 0.9985 - balanced_acc: 0.9974\n",
            "Epoch 5: val_balanced_acc did not improve from 0.49010\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9986 - balanced_acc: 0.9976 - val_loss: 0.5968 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 6/50\n",
            "246/258 [===========================>..] - ETA: 0s - loss: 0.0313 - accuracy: 0.9989 - balanced_acc: 0.9983\n",
            "Epoch 6: val_balanced_acc did not improve from 0.49010\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9990 - balanced_acc: 0.9984 - val_loss: 0.5928 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 7/50\n",
            "258/258 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9990 - balanced_acc: 0.9985\n",
            "Epoch 7: val_balanced_acc improved from 0.49010 to 0.49040, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline after smote on feature space_under70_128px.h5\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0297 - accuracy: 0.9990 - balanced_acc: 0.9985 - val_loss: 0.6222 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 5.0000e-04\n",
            "Epoch 8/50\n",
            "255/258 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9993 - balanced_acc: 0.9987\n",
            "Epoch 8: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9993 - balanced_acc: 0.9987 - val_loss: 0.5953 - val_accuracy: 0.8238 - val_balanced_acc: 0.4870 - lr: 5.0000e-04\n",
            "Epoch 9/50\n",
            "256/258 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9996 - balanced_acc: 0.9997\n",
            "Epoch 9: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9996 - balanced_acc: 0.9997 - val_loss: 0.6061 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 10/50\n",
            "252/258 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9996 - balanced_acc: 0.9974\n",
            "Epoch 10: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9996 - balanced_acc: 0.9974 - val_loss: 0.6058 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 11/50\n",
            "250/258 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9997 - balanced_acc: 0.9989\n",
            "Epoch 11: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9997 - balanced_acc: 0.9989 - val_loss: 0.6213 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 12/50\n",
            "256/258 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9999 - balanced_acc: 0.9986\n",
            "Epoch 12: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9999 - balanced_acc: 0.9986 - val_loss: 0.6409 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 5.0000e-04\n",
            "Epoch 13/50\n",
            "255/258 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9996 - balanced_acc: 0.9985\n",
            "Epoch 13: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9996 - balanced_acc: 0.9985 - val_loss: 0.6252 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 14/50\n",
            "258/258 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9998 - balanced_acc: 0.9997\n",
            "Epoch 14: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9998 - balanced_acc: 0.9997 - val_loss: 0.6242 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 15/50\n",
            "256/258 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9997 - balanced_acc: 0.9997\n",
            "Epoch 15: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9997 - balanced_acc: 0.9997 - val_loss: 0.6309 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 16/50\n",
            "258/258 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9998 - balanced_acc: 0.9992\n",
            "Epoch 16: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0212 - accuracy: 0.9998 - balanced_acc: 0.9992 - val_loss: 0.6410 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 17/50\n",
            "256/258 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9998 - balanced_acc: 0.9990\n",
            "Epoch 17: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9998 - balanced_acc: 0.9990 - val_loss: 0.6344 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 18/50\n",
            "250/258 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9998 - balanced_acc: 0.9986\n",
            "Epoch 18: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0200 - accuracy: 0.9998 - balanced_acc: 0.9987 - val_loss: 0.6437 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 19/50\n",
            "249/258 [===========================>..] - ETA: 0s - loss: 0.0195 - accuracy: 0.9999 - balanced_acc: 0.9987\n",
            "Epoch 19: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9999 - balanced_acc: 0.9987 - val_loss: 0.6400 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 20/50\n",
            "253/258 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9997 - balanced_acc: 0.9986\n",
            "Epoch 20: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9997 - balanced_acc: 0.9986 - val_loss: 0.6457 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 21/50\n",
            "253/258 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9999 - balanced_acc: 0.9993\n",
            "Epoch 21: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0183 - accuracy: 0.9998 - balanced_acc: 0.9993 - val_loss: 0.6472 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 22/50\n",
            "247/258 [===========================>..] - ETA: 0s - loss: 0.0183 - accuracy: 0.9997 - balanced_acc: 0.9992\n",
            "Epoch 22: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.9998 - balanced_acc: 0.9992 - val_loss: 0.6596 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 5.0000e-04\n",
            "Epoch 23/50\n",
            "247/258 [===========================>..] - ETA: 0s - loss: 0.0176 - accuracy: 0.9998 - balanced_acc: 0.9985\n",
            "Epoch 23: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9998 - balanced_acc: 0.9985 - val_loss: 0.6435 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 24/50\n",
            "247/258 [===========================>..] - ETA: 0s - loss: 0.0170 - accuracy: 0.9998 - balanced_acc: 0.9987\n",
            "Epoch 24: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9998 - balanced_acc: 0.9987 - val_loss: 0.6584 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 25/50\n",
            "245/258 [===========================>..] - ETA: 0s - loss: 0.0167 - accuracy: 0.9999 - balanced_acc: 0.9993\n",
            "Epoch 25: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9999 - balanced_acc: 0.9993 - val_loss: 0.6591 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 5.0000e-04\n",
            "Epoch 26/50\n",
            "246/258 [===========================>..] - ETA: 0s - loss: 0.0165 - accuracy: 0.9997 - balanced_acc: 0.9992\n",
            "Epoch 26: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 0.9998 - balanced_acc: 0.9992 - val_loss: 0.6667 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 5.0000e-04\n",
            "Epoch 27/50\n",
            "248/258 [===========================>..] - ETA: 0s - loss: 0.0161 - accuracy: 0.9998 - balanced_acc: 0.9992\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 27: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0161 - accuracy: 0.9998 - balanced_acc: 0.9993 - val_loss: 0.6657 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 5.0000e-04\n",
            "Epoch 28/50\n",
            "246/258 [===========================>..] - ETA: 0s - loss: 0.0158 - accuracy: 0.9999 - balanced_acc: 0.9982\n",
            "Epoch 28: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9999 - balanced_acc: 0.9983 - val_loss: 0.6669 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 29/50\n",
            "246/258 [===========================>..] - ETA: 0s - loss: 0.0153 - accuracy: 0.9999 - balanced_acc: 0.9993\n",
            "Epoch 29: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0154 - accuracy: 0.9999 - balanced_acc: 0.9993 - val_loss: 0.6689 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 2.5000e-04\n",
            "Epoch 30/50\n",
            "257/258 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9999 - balanced_acc: 0.9994\n",
            "Epoch 30: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0153 - accuracy: 0.9999 - balanced_acc: 0.9994 - val_loss: 0.6716 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 31/50\n",
            "250/258 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9998 - balanced_acc: 0.9998\n",
            "Epoch 31: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.0152 - accuracy: 0.9998 - balanced_acc: 0.9998 - val_loss: 0.6672 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 2.5000e-04\n",
            "Epoch 32/50\n",
            "258/258 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9999 - balanced_acc: 0.9993\n",
            "Epoch 32: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.0152 - accuracy: 0.9999 - balanced_acc: 0.9993 - val_loss: 0.6725 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 33/50\n",
            "258/258 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9999 - balanced_acc: 0.9994\n",
            "Epoch 33: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9999 - balanced_acc: 0.9994 - val_loss: 0.6718 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 34/50\n",
            "248/258 [===========================>..] - ETA: 0s - loss: 0.0150 - accuracy: 0.9998 - balanced_acc: 0.9981\n",
            "Epoch 34: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9998 - balanced_acc: 0.9982 - val_loss: 0.6699 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 35/50\n",
            "253/258 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9999 - balanced_acc: 0.9993\n",
            "Epoch 35: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.9999 - balanced_acc: 0.9993 - val_loss: 0.6744 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 36/50\n",
            "245/258 [===========================>..] - ETA: 0s - loss: 0.0146 - accuracy: 0.9999 - balanced_acc: 0.9979\n",
            "Epoch 36: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.0146 - accuracy: 0.9999 - balanced_acc: 0.9980 - val_loss: 0.6689 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 2.5000e-04\n",
            "Epoch 37/50\n",
            "249/258 [===========================>..] - ETA: 0s - loss: 0.0143 - accuracy: 0.9998 - balanced_acc: 0.9981\n",
            "Epoch 37: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9998 - balanced_acc: 0.9981 - val_loss: 0.6746 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 38/50\n",
            "256/258 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9999 - balanced_acc: 1.0000\n",
            "Epoch 38: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9999 - balanced_acc: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 39/50\n",
            "258/258 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9999 - balanced_acc: 0.9982\n",
            "Epoch 39: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9999 - balanced_acc: 0.9982 - val_loss: 0.6769 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 2.5000e-04\n",
            "Epoch 40/50\n",
            "253/258 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9998 - balanced_acc: 0.9981\n",
            "Epoch 40: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9998 - balanced_acc: 0.9981 - val_loss: 0.6816 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 41/50\n",
            "257/258 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9999 - balanced_acc: 0.9999\n",
            "Epoch 41: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9999 - balanced_acc: 0.9999 - val_loss: 0.6790 - val_accuracy: 0.8187 - val_balanced_acc: 0.4859 - lr: 2.5000e-04\n",
            "Epoch 42/50\n",
            "246/258 [===========================>..] - ETA: 0s - loss: 0.0138 - accuracy: 0.9999 - balanced_acc: 0.9993\n",
            "Epoch 42: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9999 - balanced_acc: 0.9994 - val_loss: 0.6774 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 43/50\n",
            "252/258 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9999 - balanced_acc: 0.9993\n",
            "Epoch 43: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.9999 - balanced_acc: 0.9993 - val_loss: 0.6768 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 44/50\n",
            "257/258 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9998 - balanced_acc: 0.9981\n",
            "Epoch 44: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0135 - accuracy: 0.9998 - balanced_acc: 0.9982 - val_loss: 0.6864 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 45/50\n",
            "252/258 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9999 - balanced_acc: 0.9992\n",
            "Epoch 45: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0135 - accuracy: 0.9999 - balanced_acc: 0.9992 - val_loss: 0.6852 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 46/50\n",
            "245/258 [===========================>..] - ETA: 0s - loss: 0.0132 - accuracy: 0.9999 - balanced_acc: 0.9993\n",
            "Epoch 46: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0131 - accuracy: 0.9999 - balanced_acc: 0.9994 - val_loss: 0.6839 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 47/50\n",
            "253/258 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9998 - balanced_acc: 0.9993\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 47: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9998 - balanced_acc: 0.9993 - val_loss: 0.6809 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 2.5000e-04\n",
            "Epoch 48/50\n",
            "247/258 [===========================>..] - ETA: 0s - loss: 0.0129 - accuracy: 0.9999 - balanced_acc: 0.9987\n",
            "Epoch 48: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9999 - balanced_acc: 0.9988 - val_loss: 0.6834 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 1.2500e-04\n",
            "Epoch 49/50\n",
            "257/258 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9999 - balanced_acc: 0.9993\n",
            "Epoch 49: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9999 - balanced_acc: 0.9993 - val_loss: 0.6879 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 1.2500e-04\n",
            "Epoch 50/50\n",
            "247/258 [===========================>..] - ETA: 0s - loss: 0.0128 - accuracy: 0.9999 - balanced_acc: 0.9993\n",
            "Epoch 50: val_balanced_acc did not improve from 0.49040\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9999 - balanced_acc: 0.9993 - val_loss: 0.6872 - val_accuracy: 0.8238 - val_balanced_acc: 0.4904 - lr: 1.2500e-04\n"
          ]
        }
      ],
      "source": [
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"best_model_fpath:\"+best_model_fpath)\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"last_model_fpath:\"+last_model_fpath)\n",
        "mc1 = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=40,monitor='val_balanced_acc')\n",
        "model2.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst = model2.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    #callbacks=[learning_rate_reduction,early_stopping_monitor, mc1])\n",
        "                    callbacks=[learning_rate_reduction,mc1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "8XhlbWn--8Or",
        "outputId": "f786739b-ea81-4207-e594-760924158aa4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "u-x0SENPGmm9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "model2.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-e3ZaeeG1Bf",
        "outputId": "03428ec0-38d5-44ef-97e8-99b2d816c7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "517/517 [==============================] - 1s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "accuracy on training 0.9998789492797482\n",
            "balanced accuracy on training 0.9998857142857143\n",
            "accuracy on validation 0.8238341968911918\n",
            "balanced accuracy on validation 0.7589544021599771\n",
            "Score on val data:  (0.7262599334027905, 0.7589544021599771, 0.7169230769230769, None)\n"
          ]
        }
      ],
      "source": [
        "#last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_smote on feature space_under70_224px.h5'\n",
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ3baQLsHLat",
        "outputId": "9cc702a0-271a-412d-9818-0ecb221d211b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "517/517 [==============================] - 1s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "accuracy on training 0.9995157971189929\n",
            "balanced accuracy on training 0.9995428571428572\n",
            "accuracy on validation 0.8238341968911918\n",
            "balanced accuracy on validation 0.7589544021599771\n",
            "Score on val data:  (0.7103722564929462, 0.7589544021599771, 0.6973531844499586, None)\n"
          ]
        }
      ],
      "source": [
        "#best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_smote on feature space_under70_224px.h5'\n",
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load ISIC 2018 Challange Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3P7IjyLuZGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74bd3c97-fa20-4449-ccd2-85987855e080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 32, 32, 3)\n",
            "(5321, 7)\n",
            "(193, 32, 32, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train, X_val, y_val = load_isic2018_dataset(train_under_frac = train_under_frac)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT95XFaHQD6d"
      },
      "outputs": [],
      "source": [
        "X_train = preprocess_image_input(X_train, the_arch)\n",
        "X_val = preprocess_image_input(X_val, the_arch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APHFdj25vatJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c7433a-f6b6-489a-b5c1-5a5625ae96d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset saved: under70_224px\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "df1.to_pickle(path+\"isic2018_train_\"+dataset_name+\".pkl\")\n",
        "df2.to_pickle(path+\"isic2018_val_\"+dataset_name+\".pkl\")\n",
        "print(\"dataset saved:\", dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IncA-_o_n5w"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_train.value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(y_train == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df1['y_train'].unique())\n",
        "for label in range(7):\n",
        "    plot_images_per_label(df1, label, 3, (12,9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asV1O58Lrq-R"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.fromarray(X_train[0], 'RGB')\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmX_Uqbmj-tN"
      },
      "outputs": [],
      "source": [
        "from numpy import moveaxis\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_el = np.inf\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = EPOCHS       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "args['patience'] = 20"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder\n",
        "H_in= 7\n",
        "stride = 2\n",
        "padding = 1\n",
        "dilation = 1\n",
        "kernel_size = 4\n",
        "output_padding=0\n",
        "H_out = (H_in - 1)*stride - 2*padding + dilation*(kernel_size-1) + output_padding + 1\n",
        "print (H_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cufzPasvtkv",
        "outputId": "3a7afd26-31fd-4ed9-d6b3-77fe3edf0b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder\n",
        "W=4\n",
        "K=4\n",
        "S=1\n",
        "P=0\n",
        "Wout = ((W-K+2*P)/S)+1\n",
        "print(Wout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQJu5JSm1HMv",
        "outputId": "989faf8e-5e3c-4b86-d6e5-e7c954d94bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NydOdPMajEfT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        # [(W−K+2P)/S]+1\n",
        "        self.conv = nn.Sequential(\n",
        "            #nn.AvgPool2d(7, stride=7),\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 5, 3, 0, bias=False),# 42\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 5, 3, 1, bias=False), # 14\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 5, 3, 0, bias=False),# 4\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 1, 0, bias=False),#1\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.fc = nn.Linear(self.dim_h * 8, self.n_z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 3 * 3),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        # H_out ​= (H_in​−1)*stride[0] − 2×padding[0] + dilation[0]×(kernel_size[0]−1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 3,2,0), #7\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4,2,1), #14\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.dim_h, 5,3,1), #42\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h, 3, 5,3,0),# 128\n",
        "            #nn.BatchNorm2d(self.dim_h),\n",
        "            #nn.ReLU(True),\n",
        "            #nn.ConvTranspose2d(self.dim_h, 3, 4, 2, 1),# 32\n",
        "            #nn.UpsamplingBilinear2d(scale_factor=7),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 3, 3)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def DeepSMOTE_train(X_train, y_train, one_hot = False):\n",
        "  from torch.utils.data import TensorDataset\n",
        "  import os\n",
        "\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #X_train = X_train.astype('float32') / 255.\n",
        "  \n",
        "  batch_size = args['batch_size']\n",
        "  patience = args['patience']\n",
        "  encoder = Encoder(args)\n",
        "  decoder = Decoder(args)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print(device)\n",
        "  decoder = decoder.to(device)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "  #decoder loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  tensor_x = torch.from_numpy(X_train.copy())#torch.Tensor(X_train)\n",
        "  tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "  mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "      batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "  dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      train_loss = 0.0\n",
        "      tmse_loss = 0.0\n",
        "      tdiscr_loss = 0.0\n",
        "      # train for one epoch -- set nets to train mode\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "  \n",
        "      for images,labs in train_loader:\n",
        "      \n",
        "          # zero gradients for each batch\n",
        "          encoder.zero_grad()\n",
        "          decoder.zero_grad()\n",
        "          images, labs = images.to(device), labs.to(device)\n",
        "          labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "          # run images\n",
        "          z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "      \n",
        "          x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "          mse = criterion(x_hat,images)\n",
        "                  \n",
        "          resx = []\n",
        "          resy = []\n",
        "      \n",
        "          tc = np.random.choice(num_classes,1)\n",
        "          #tc = 9\n",
        "          xbeg = X_train[y_train == tc]\n",
        "          ybeg = y_train[y_train == tc] \n",
        "          xlen = len(xbeg)\n",
        "          nsamp = min(xlen, 100)\n",
        "          ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "          xclass = xbeg[ind]\n",
        "          yclass = ybeg[ind]\n",
        "      \n",
        "          xclen = len(xclass)\n",
        "          xcminus = np.arange(1,xclen)\n",
        "          \n",
        "          xcplus = np.append(xcminus,0)\n",
        "          xcnew = (xclass[[xcplus],:])\n",
        "          xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "      \n",
        "          xcnew = torch.Tensor(xcnew)\n",
        "          xcnew = xcnew.to(device)\n",
        "      \n",
        "          #encode xclass to feature space\n",
        "          xclass = torch.Tensor(xclass)\n",
        "          xclass = xclass.to(device)\n",
        "          xclass = encoder(xclass)\n",
        "      \n",
        "          xclass = xclass.detach().cpu().numpy()\n",
        "      \n",
        "          xc_enc = (xclass[[xcplus],:])\n",
        "          xc_enc = np.squeeze(xc_enc)\n",
        "      \n",
        "          xc_enc = torch.Tensor(xc_enc)\n",
        "          xc_enc = xc_enc.to(device)\n",
        "          \n",
        "          ximg = decoder(xc_enc)\n",
        "          \n",
        "          mse2 = criterion(ximg,xcnew)\n",
        "      \n",
        "          comb_loss = mse2 + mse\n",
        "          comb_loss.backward()\n",
        "      \n",
        "          enc_optim.step()\n",
        "          dec_optim.step()\n",
        "      \n",
        "          train_loss += comb_loss.item()*images.size(0)\n",
        "          tmse_loss += mse.item()*images.size(0)\n",
        "          tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      tmse_loss = tmse_loss/len(train_loader)\n",
        "      tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "      print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "              train_loss,tmse_loss,tdiscr_loss))\n",
        "      \n",
        "  \n",
        "  \n",
        "      #store the best encoder and decoder models\n",
        "      #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "      #necessary for illustration purposes\n",
        "      if train_loss < best_loss:\n",
        "          print('Saving best encoder - decoder')\n",
        "          patience = args['patience']\n",
        "          path_enc = '/content/drive/MyDrive/PHD/Model/best_enc_'+exp_name+'_'+dataset_name+'.pth'\n",
        "          path_dec = '/content/drive/MyDrive/PHD/Model/best_dec_'+exp_name+'_'+dataset_name+'.pth'\n",
        "        \n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "  \n",
        "          best_loss = train_loss\n",
        "      else:\n",
        "          patience = patience - 1\n",
        "\n",
        "      if patience == 0:\n",
        "          print('Out of patience. \\n')\n",
        "          break\n",
        "  print('Saving last encoder - decoder')\n",
        "  path_enc = '/content/drive/MyDrive/PHD/Model/last_enc_'+exp_name+'_'+dataset_name+'.pth'\n",
        "  path_dec = '/content/drive/MyDrive/PHD/Model/last_dec_'+exp_name+'_'+dataset_name+'.pth'\n",
        "\n",
        "  torch.save(encoder.state_dict(), path_enc)\n",
        "  torch.save(decoder.state_dict(), path_dec)\n",
        "\n",
        "def DeepSMOTE_Data(X_train, y_train, one_hot = False, use_model=\"best\"):\n",
        "  batch_size = args['batch_size']\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #Generate artificial images\n",
        "  import torch\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "  #path on the computer where the models are stored\n",
        "  if use_model == 'best':\n",
        "    path_enc = '/content/drive/MyDrive/PHD/Model/best_enc_'+exp_name+'_'+dataset_name+'.pth'\n",
        "    path_dec = '/content/drive/MyDrive/PHD/Model/best_dec_'+exp_name+'_'+dataset_name+'.pth'\n",
        "  else:\n",
        "    path_enc = '/content/drive/MyDrive/PHD/Model/last_enc_'+exp_name+'_'+dataset_name+'.pth'\n",
        "    path_dec = '/content/drive/MyDrive/PHD/Model/last_dec_'+exp_name+'_'+dataset_name+'.pth'\n",
        "  \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  print(\"Load model: \", path_enc)\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  print(\"Load model: \", path_dec)\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  \n",
        "  counter = Counter(y_train)\n",
        "  counter = sorted(counter.items())\n",
        "  counter = [value for _, value in counter]\n",
        "\n",
        "  for i in range(num_classes):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      n = np.max(counter) - counter[i]\n",
        "      if n == 0:\n",
        "        continue\n",
        "#        resx2 = []\n",
        "#        resy2 = []\n",
        "#        for j in range(batch_size, n+batch_size+1, batch_size):\n",
        "#          if j <= n:\n",
        "#            batch_size_max = batch_size\n",
        "#          elif n % batch_size != 0:\n",
        "#            batch_size_max = n%batch_size\n",
        "#          else:\n",
        "#            break\n",
        "#          xsamp, ysamp = G_SM(xclass,yclass,batch_size_max,i)\n",
        "      xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "      ysamp = np.array(ysamp)\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "#        resx2.append(ximn)\n",
        "#        resy2.append(ysamp)\n",
        "#        \n",
        "#        resx2 = np.vstack(resx2)\n",
        "#        resy2 = np.hstack(resy2)\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "  X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "  X_train = np.vstack((resx1,X_train))\n",
        "  y_train = np.hstack((resy1,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "  X_train = moveaxis(X_train, 1, 3)\n",
        "  X_train = X_train * max_el\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DeepSMOTE_train(X_train, y_train, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD5EzeV4y0Iq",
        "outputId": "b753ac0a-ebed-44f6-8653-c096679c6d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch: 0 \tTrain Loss: 24.725033 \tmse loss: 12.203676 \tmse2 loss: 12.521357\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 1 \tTrain Loss: 9.230754 \tmse loss: 4.558404 \tmse2 loss: 4.672350\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 2 \tTrain Loss: 5.676908 \tmse loss: 2.730959 \tmse2 loss: 2.945949\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 3 \tTrain Loss: 4.486106 \tmse loss: 2.134804 \tmse2 loss: 2.351302\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 4 \tTrain Loss: 3.623292 \tmse loss: 1.611530 \tmse2 loss: 2.011762\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 5 \tTrain Loss: 3.129885 \tmse loss: 1.374469 \tmse2 loss: 1.755415\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 6 \tTrain Loss: 2.788804 \tmse loss: 1.213340 \tmse2 loss: 1.575464\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 7 \tTrain Loss: 2.747276 \tmse loss: 1.168496 \tmse2 loss: 1.578780\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 8 \tTrain Loss: 2.521208 \tmse loss: 1.073430 \tmse2 loss: 1.447778\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 9 \tTrain Loss: 2.430718 \tmse loss: 1.069310 \tmse2 loss: 1.361408\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 10 \tTrain Loss: 2.390305 \tmse loss: 1.003383 \tmse2 loss: 1.386922\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 11 \tTrain Loss: 2.297638 \tmse loss: 0.947754 \tmse2 loss: 1.349884\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 12 \tTrain Loss: 2.211478 \tmse loss: 0.942759 \tmse2 loss: 1.268719\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 13 \tTrain Loss: 2.224302 \tmse loss: 0.939262 \tmse2 loss: 1.285039\n",
            "Saving last encoder - decoder\n",
            "Epoch: 14 \tTrain Loss: 2.091953 \tmse loss: 0.871941 \tmse2 loss: 1.220012\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 15 \tTrain Loss: 2.044284 \tmse loss: 0.854714 \tmse2 loss: 1.189570\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 16 \tTrain Loss: 2.097986 \tmse loss: 0.878664 \tmse2 loss: 1.219322\n",
            "Saving last encoder - decoder\n",
            "Epoch: 17 \tTrain Loss: 2.098824 \tmse loss: 0.875717 \tmse2 loss: 1.223107\n",
            "Saving last encoder - decoder\n",
            "Epoch: 18 \tTrain Loss: 1.995100 \tmse loss: 0.817802 \tmse2 loss: 1.177298\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 19 \tTrain Loss: 1.897978 \tmse loss: 0.833374 \tmse2 loss: 1.064604\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 20 \tTrain Loss: 1.891092 \tmse loss: 0.827801 \tmse2 loss: 1.063291\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 21 \tTrain Loss: 1.802419 \tmse loss: 0.814558 \tmse2 loss: 0.987861\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 22 \tTrain Loss: 1.867575 \tmse loss: 0.822895 \tmse2 loss: 1.044680\n",
            "Saving last encoder - decoder\n",
            "Epoch: 23 \tTrain Loss: 1.853053 \tmse loss: 0.840036 \tmse2 loss: 1.013017\n",
            "Saving last encoder - decoder\n",
            "Epoch: 24 \tTrain Loss: 1.822306 \tmse loss: 0.808471 \tmse2 loss: 1.013836\n",
            "Saving last encoder - decoder\n",
            "Epoch: 25 \tTrain Loss: 1.729070 \tmse loss: 0.766862 \tmse2 loss: 0.962208\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 26 \tTrain Loss: 1.629938 \tmse loss: 0.721505 \tmse2 loss: 0.908434\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 27 \tTrain Loss: 1.643633 \tmse loss: 0.734480 \tmse2 loss: 0.909153\n",
            "Saving last encoder - decoder\n",
            "Epoch: 28 \tTrain Loss: 1.708623 \tmse loss: 0.778945 \tmse2 loss: 0.929679\n",
            "Saving last encoder - decoder\n",
            "Epoch: 29 \tTrain Loss: 1.633916 \tmse loss: 0.725230 \tmse2 loss: 0.908686\n",
            "Saving last encoder - decoder\n",
            "Epoch: 30 \tTrain Loss: 1.582657 \tmse loss: 0.716852 \tmse2 loss: 0.865805\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 31 \tTrain Loss: 1.573767 \tmse loss: 0.692442 \tmse2 loss: 0.881324\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 32 \tTrain Loss: 1.474086 \tmse loss: 0.667319 \tmse2 loss: 0.806767\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 33 \tTrain Loss: 1.445649 \tmse loss: 0.663813 \tmse2 loss: 0.781836\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 34 \tTrain Loss: 1.383388 \tmse loss: 0.630146 \tmse2 loss: 0.753241\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 35 \tTrain Loss: 1.476357 \tmse loss: 0.675651 \tmse2 loss: 0.800706\n",
            "Saving last encoder - decoder\n",
            "Epoch: 36 \tTrain Loss: 1.394161 \tmse loss: 0.642319 \tmse2 loss: 0.751842\n",
            "Saving last encoder - decoder\n",
            "Epoch: 37 \tTrain Loss: 1.380749 \tmse loss: 0.632166 \tmse2 loss: 0.748583\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 38 \tTrain Loss: 1.405232 \tmse loss: 0.643845 \tmse2 loss: 0.761387\n",
            "Saving last encoder - decoder\n",
            "Epoch: 39 \tTrain Loss: 1.286873 \tmse loss: 0.604482 \tmse2 loss: 0.682391\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 40 \tTrain Loss: 1.355868 \tmse loss: 0.637045 \tmse2 loss: 0.718822\n",
            "Saving last encoder - decoder\n",
            "Epoch: 41 \tTrain Loss: 1.371825 \tmse loss: 0.653038 \tmse2 loss: 0.718786\n",
            "Saving last encoder - decoder\n",
            "Epoch: 42 \tTrain Loss: 1.348737 \tmse loss: 0.625337 \tmse2 loss: 0.723400\n",
            "Saving last encoder - decoder\n",
            "Epoch: 43 \tTrain Loss: 1.286499 \tmse loss: 0.616462 \tmse2 loss: 0.670037\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 44 \tTrain Loss: 1.347290 \tmse loss: 0.618123 \tmse2 loss: 0.729166\n",
            "Saving last encoder - decoder\n",
            "Epoch: 45 \tTrain Loss: 1.357875 \tmse loss: 0.633765 \tmse2 loss: 0.724111\n",
            "Saving last encoder - decoder\n",
            "Epoch: 46 \tTrain Loss: 1.223423 \tmse loss: 0.580502 \tmse2 loss: 0.642921\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n",
            "Epoch: 47 \tTrain Loss: 1.257264 \tmse loss: 0.578815 \tmse2 loss: 0.678449\n",
            "Saving last encoder - decoder\n",
            "Epoch: 48 \tTrain Loss: 1.266337 \tmse loss: 0.595284 \tmse2 loss: 0.671052\n",
            "Saving last encoder - decoder\n",
            "Epoch: 49 \tTrain Loss: 1.194296 \tmse loss: 0.570200 \tmse2 loss: 0.624096\n",
            "Saving best encoder - decoder\n",
            "Saving last encoder - decoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = DeepSMOTE_Data(X_train, y_train, one_hot = True, use_model=\"best\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEqp4T2-7jVE",
        "outputId": "ecb5714b-648b-45e5-ea88-511ee90d89ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load model:  /content/drive/MyDrive/PHD/Model/best_enc_deep smote_under70_128px.pth\n",
            "Load model:  /content/drive/MyDrive/PHD/Model/best_dec_deep smote_under70_128px.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6qneWL_Bs2U"
      },
      "outputs": [],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1jnSM7yzJc"
      },
      "outputs": [],
      "source": [
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['balanced_acc'])\n",
        "plt.plot(hst2.history['val_balanced_acc'])\n",
        "plt.title('model balance_acc after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BE9FCWBe8deT",
        "3K908bbiYwbS",
        "UswA0co2y1wl",
        "LfcFpsBwM0d4",
        "cNBXx28B9yGu",
        "0jrJ33lUDkCM",
        "B2PgksTFkOAq"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}